{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing Required Dependencies\n",
        "\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install datasets\n",
        "\n",
        "# Importing dependencies\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn.functional as F\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "BGGRelQABzm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the News data file\n",
        "df_news = pd.read_csv('sts_news.csv')\n",
        "\n",
        "# Reading the Sports data file\n",
        "df_sports = pd.read_csv('sts_sports.csv')\n",
        "\n",
        "# Importing Biomedical data from Huggingface Datasets\n",
        "biosses_sts = 'mteb/biosses-sts'\n",
        "dataset_biosses_sts = load_dataset(biosses_sts, split=\"test\")\n",
        "\n",
        "# Changing column names so that each data in formatted in similar fashion\n",
        "new_column_names = ['sentence1', 'sentence2', 'score']\n",
        "\n",
        "# Assign new column names to the news dataset\n",
        "df_news.columns = new_column_names\n",
        "\n",
        "# Assign new column names to the sports dataset\n",
        "df_sports.columns = new_column_names\n",
        "\n",
        "# Assigning model\n",
        "model_name_bert = \"bert-base-uncased\""
      ],
      "metadata": {
        "id": "Iynxy8ZrB6Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Train Test Splits for News dataset\n",
        "train_df_news, test_df_news = train_test_split(df_news, test_size=0.2, random_state=21)\n",
        "train_df_news = train_df_news.reset_index(drop=True)\n",
        "test_df_news = test_df_news.reset_index(drop=True)\n",
        "\n",
        "# Creating Train Test Splits for Biosses dataset\n",
        "train_bio, test_bio = train_test_split(dataset_biosses_sts, test_size=0.2, random_state=21)\n",
        "# Converting Biosses data from dictionary to pandas dataframe\n",
        "train_df_bio = pd.DataFrame(train_bio)\n",
        "test_df_bio = pd.DataFrame(test_bio)\n",
        "\n",
        "# Creating Train Test Splits for Sports dataset\n",
        "train_df_sports, test_df_sports = train_test_split(df_sports, test_size=0.2, random_state=21)\n",
        "train_df_sports = train_df_sports.reset_index(drop=True)\n",
        "test_df_sports = test_df_sports.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "v7xAfvoVUoix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSTS(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_classes, hidden_size):\n",
        "        super(BertForSTS, self).__init__()\n",
        "        # Use the pretrained BERT model\n",
        "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
        "        # Add a Linear Layer on toop of the BERT model for fine tuning\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)  # Adding fully connected layers for fine-tuning\n",
        "        # Cosine Similarity score to be computed\n",
        "        self.cosine_similarity = nn.CosineSimilarity(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n",
        "        # Sentence embeddings passed to the BERT model to get the outputs of Sentence 1\n",
        "        outputs1 = self.bert(input_ids=input_ids1, attention_mask=attention_mask1)\n",
        "        # Apply mean pooling\n",
        "        token_embeddings1 = outputs1[0] #First element of model_output contains all token embeddings\n",
        "        input_mask_expanded = attention_mask1.unsqueeze(-1).expand(token_embeddings1.size()).float()\n",
        "        sum_embeddings = torch.sum(token_embeddings1 * input_mask_expanded,1)\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "        pooled_output1 =  sum_embeddings/sum_mask\n",
        "\n",
        "        # Sentence embeddings passed to the BERT model to get the outputs of Sentence 2\n",
        "        outputs2 = self.bert(input_ids=input_ids2, attention_mask=attention_mask2)\n",
        "        # Apply mean pooling\n",
        "        token_embeddings2 = outputs2[0] #First element of model_output contains all token embeddings\n",
        "        input_mask_expanded = attention_mask2.unsqueeze(-1).expand(token_embeddings2.size()).float()\n",
        "        sum_embeddings = torch.sum(token_embeddings2 * input_mask_expanded,1)\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "        pooled_output2 =  sum_embeddings/sum_mask\n",
        "\n",
        "        # Pass the outputs from the BERT model to perform the Linear Transformations as a additional head for fine tuning on Sentence 1 and 2\n",
        "        pooled_output1 = self.fc1(pooled_output1)\n",
        "        pooled_output2 = self.fc1(pooled_output2)\n",
        "\n",
        "        # Calculate cosine similarity scores between the 2 sentences\n",
        "        similarity_scores = self.cosine_similarity(pooled_output1, pooled_output2)\n",
        "\n",
        "        return similarity_scores\n"
      ],
      "metadata": {
        "id": "_mRSC5bpYUD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSpearmanCorr(dataset,modelName):\n",
        "  # Lists to store predicted and true similarity scores\n",
        "  predicted_scores = []\n",
        "  true_scores = dataset[\"score\"]\n",
        "\n",
        "  # Load pre-trained model and tokenizer\n",
        "  model_name = modelName\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  model = BertForSTS(model_name, num_classes=1, hidden_size=768)\n",
        "  criterion = nn.MSELoss() # Use CrossEntropyLoss for classification tasks\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  total_loss = 0\n",
        "  for i in range(len(dataset)):\n",
        "    #Sentences we want sentence embeddings for\n",
        "    Sentence1 = [dataset[\"sentence1\"][i]]\n",
        "    Sentence2 = [dataset[\"sentence2\"][i]]\n",
        "\n",
        "    #Tokenize sentences\n",
        "    encoded_input1 = tokenizer(Sentence1, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "    encoded_input2 = tokenizer(Sentence2, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #Computing Similarity Score\n",
        "    similarity_score = model(encoded_input1['input_ids'], encoded_input1['attention_mask'],encoded_input2['input_ids'],encoded_input2['attention_mask'])\n",
        "    # Rescale the score from (-1,1) to (0,1) to match the targets.\n",
        "    rescaled_similarity_score = (similarity_score + 1)/2\n",
        "\n",
        "    similarity_score_tensor = torch.tensor([rescaled_similarity_score], dtype=torch.float32, requires_grad=True)\n",
        "    target_score_tensor = torch.tensor([dataset[\"score\"][i]], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # Compute the loss for each instance\n",
        "    loss = criterion(similarity_score_tensor, target_score_tensor)\n",
        "\n",
        "    # Compute the total loss\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return total_loss / len(dataset), model"
      ],
      "metadata": {
        "id": "utmrNPTVPMbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testgetSpearmanCorr(dataset,func_model):\n",
        "  # Lists to store predicted and true similarity scores\n",
        "  predicted_scores = []\n",
        "  true_scores = dataset[\"score\"]\n",
        "\n",
        "  # Load domain specific trained model and tokenizer\n",
        "  model = func_model\n",
        "  tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  for i in range(len(dataset)):\n",
        "    #Sentences we want sentence embeddings for\n",
        "    Sentence1 = [dataset[\"sentence1\"][i]]\n",
        "    Sentence2 = [dataset[\"sentence2\"][i]]\n",
        "\n",
        "    #Tokenize sentences\n",
        "    encoded_input1 = tokenizer(Sentence1, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "    encoded_input2 = tokenizer(Sentence2, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "    similarity_score = model(encoded_input1['input_ids'], encoded_input1['attention_mask'],encoded_input2['input_ids'],encoded_input2['attention_mask'])\n",
        "    rescaled_similarity_score = (similarity_score + 1)/2\n",
        "    rescaled_similarity_score = rescaled_similarity_score.detach().numpy()\n",
        "\n",
        "    # Store predicted and true similarity scores\n",
        "    predicted_scores.append(rescaled_similarity_score)\n",
        "\n",
        "    # Calculate Spearman rank correlation coefficient\n",
        "  spearman_corr, _ = spearmanr(true_scores, predicted_scores)\n",
        "  return spearman_corr"
      ],
      "metadata": {
        "id": "CkFpd5h5d-M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Custom Model Specific for News Data"
      ],
      "metadata": {
        "id": "6lcYV69JiyL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, model_news = getSpearmanCorr(train_df_news, model_name_bert)"
      ],
      "metadata": {
        "id": "TQsJxEMQcBq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Loss for News Domain Data is: \",loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC29PtL2g2xO",
        "outputId": "c720abfb-eeb1-42fb-ae62-d9c3de3e7ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for News Domain Data is:  0.18390363676371635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Custom Model Specific for News Data"
      ],
      "metadata": {
        "id": "YVicnISJkU4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_news.eval()\n",
        "corr_for_news = testgetSpearmanCorr(test_df_news, model_news)\n",
        "print(\"Spearman Coorelation for scores given by Domain Specific(News) Model is: \", corr_for_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_q5qDe9h8Qm",
        "outputId": "2f2d7d96-c2cf-4463-945d-8e1110fb09e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Coorelation for scores given by Domain Specific(News) Model is:  0.37811589973119136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Custom Model Specific for Biomedical Data"
      ],
      "metadata": {
        "id": "wxDeL4h8kPae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, model_bio = getSpearmanCorr(train_df_bio, model_name_bert)"
      ],
      "metadata": {
        "id": "jaeEJxvxT4US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Loss for Biomedical Domain Data is: \",loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOORFPMhUA35",
        "outputId": "5eeeba8a-b1ee-498f-d193-b62b0a19dc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Biomedical Domain Data is:  3.03235981304897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Custom Model Specific for Biomedical Data"
      ],
      "metadata": {
        "id": "YiDnNFt5lDBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bio.eval()\n",
        "corr_for_bio = testgetSpearmanCorr(test_df_bio, model_bio)\n",
        "print(\"Spearman Coorelation for scores given by Domain Specific(News) Model is: \", corr_for_bio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDp5Py-lUf8R",
        "outputId": "8f41f539-e2ea-4fea-8459-efd970e0460e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Coorelation for scores given by Domain Specific(News) Model is:  0.5851763367832985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Custom Model Specific for Sports Data"
      ],
      "metadata": {
        "id": "Pcx217t1lWUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, model_sports = getSpearmanCorr(train_df_sports, model_name_bert)"
      ],
      "metadata": {
        "id": "iJS95XrKZWtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Loss for Sports Domain Data is: \",loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5MdkudjZbRD",
        "outputId": "11ac5f69-640a-4491-97a7-0ad65e315514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Sports Domain Data is:  0.13146289361627125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Custom Model Specific for Sports Data"
      ],
      "metadata": {
        "id": "qaikP-ntl81N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sports.eval()\n",
        "corr_for_sports = testgetSpearmanCorr(test_df_sports, model_sports)\n",
        "print(\"Spearman Coorelation for scores given by Domain Specific(News) Model is: \", corr_for_sports)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LadQsnHZmnJ",
        "outputId": "f0960a33-c4e0-4650-bf9e-25c4dff0e38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Coorelation for scores given by Domain Specific(News) Model is:  0.25019823829630605\n"
          ]
        }
      ]
    }
  ]
}